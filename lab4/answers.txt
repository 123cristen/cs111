CS111 Lab 4

Part 1:

QUESTIONS 1.1

1) It takes a large number of iterations/threads for an error
to occur because race conditions are more likely to result in
errors the more times they occur. In this case, the more times
the global variable counter is modified by different threads,
the more likely they are to write over each other. In my tests,
I set threads to 10 and iterations to 500 to cause consistent
failure.

2) A significantly smaller number of iterations seldom fails
because it is more likely that the race conditions will not
result in an incorrect value. For example, if iterations is 1,
and there are 3 threads, imagine if thread 2 reads the value of 
counter to be zero. Before it can update the counter to 1, 
thread 2 sets the counter to 1 and then back to 0. Then 
thread 1 will correctly update counter to 1, so even though
there were race conditions the result will be correct in the
end. These types of coincidences are more likely when there
is a smaller range for counter, which happens when the number
of iterations is smaller.

QUESTIONS 1.2

1) The average cost per operation drops with increasing iterations
because because the thread creation overhead starts to become
less of a percentage of total cost. When there are just a few 
iterations, thread overhead might be half of the overall
operation cost, whereas with many iterations the thread
overhead might just be 5% of the total cost. 

2) The correct cost is the total cost minus the overhead 
of thread creation. We could figure this out by getting the clock
time before and after pthread_create, multiplying by the number
of threads and then subtracting this from the total cost. 

3) --yield operations are much slower because there is a lot
of time spent on context switching between threads. The extra
time is spent in thread overhead.

4) We cannot get valid timings if we are using yield. There
is no way to find the time spent in overhead in switching
contexts, because we do not know what thread will be switched
to and when. Because of this, we cannot find the time before
and after switching contexts in order to calculate the time
taken to do so. Without subtracting the time spent in context
switches, we cannot have a valid timing.

QUESTIONS 1.3

1) For low numbers of threads, the operations will perform similarly
because they will not have to wait as long to grab a lock or for 
compare_and_swap to return successfully. This is because there
are not as many threads trying to grab a lock simultaneously.

2) The three protected operations slow down as the thread count
rises for two different reasons. The mutex and spinlock versions
are slow because if only one thread can have the lock at a time,
it means that with many threads there is a higher demand on the
lock and more time is spent waiting to access the lock. For the
compare_and_swap version, with more threads there is higher chance
of another thread modifying counter during the same time, which
means that compare_and_swap will continue to fail for a longer 
time which causes the program to run longer.

3) Spinlocks are so expensive for large numbers of threads because
they implement busy waiting, where they take CPU resources while
waiting for the lock. With large number of threads, more time will
be spent waiting for a single lock, and thus more resources will
be used.
